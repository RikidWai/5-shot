{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "CS480 Kaggle Competition \n",
    "==============================="
   ],
   "metadata": {
    "id": "2K9muD4NgQX-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Name: Ricky Chu\n",
    "\n",
    "SID: 20987513\n",
    "\n",
    "Email: r2chu@uwaterloo.ca\n"
   ],
   "metadata": {
    "id": "gKmZ5NQtf_qu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(1) Load Data  \n",
    "--------------------"
   ],
   "metadata": {
    "id": "2bwNvIPGgj0J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "import pandas as pd \n",
    "from google.colab import files\n",
    "import csv \n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters \n",
    "batch_size = 8\n",
    "learning_rate = 2e-4\n",
    "num_of_epochs = 10\n",
    "ROOT_PATH = \"drive/MyDrive/Kaggle/\"\n",
    "\n",
    "cnn = resnet50(pretrained=True).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "total_train_loss= []\n",
    "total_train_acc=[]\n",
    "\n",
    "# Custom Data Loader\n",
    "class TestData(Dataset):\n",
    "    def __init__(self, dir, transform):\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        self.all_imgs = os.listdir(dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.dir, self.all_imgs[idx])\n",
    "        id = os.path.basename(img_loc[:-4])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image,id\n",
    "\n",
    "# Load Data\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=ROOT_PATH+'5_shot/train',\n",
    "    transform=transforms.Compose([transforms.ToTensor()],\n",
    "    )\n",
    ")\n",
    "\n",
    "test_data = TestData(dir=ROOT_PATH+'5_shot/test', transform=transforms.ToTensor())\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=0,\n",
    "                        shuffle = True \n",
    "                        ),\n",
    "           \n",
    "\n",
    "    'test': DataLoader(test_data,\n",
    "                       batch_size=1,\n",
    "                       num_workers=0),\n",
    "}"
   ],
   "metadata": {
    "id": "X8rjcxmkguqY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2) Train \n",
    "--------------------"
   ],
   "metadata": {
    "id": "zhLlNRW1gYbu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "GGE5WdY64CAi",
    "outputId": "b64e4a15-3dc9-4024-e81b-c26e452ceb37"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch\tAccuracy\tLoss\n",
      "1\t0.28182\t4.51436\n",
      "2\t0.86364\t0.67096\n",
      "3\t0.95455\t0.27634\n",
      "4\t0.96364\t0.15865\n",
      "5\t0.95455\t0.13994\n",
      "6\t1.0\t0.05449\n",
      "7\t1.0\t0.03966\n",
      "8\t1.0\t0.02949\n",
      "9\t1.0\t0.01989\n",
      "10\t1.0\t0.01038\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "download(\"download_deae0ebb-461d-4741-a9a2-da025963372f\", \"Resnet50model.pth\", 102544897)"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    train_loss, correct = 0, 0\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        # gives batch data, normalize x when iterate train_loader\n",
    "        X = images.to(device)  # batch x\n",
    "        y = labels.to(device)  # batch y\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # record loss\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    total_train_loss.append(train_loss)\n",
    "    correct /= size\n",
    "    total_train_acc.append(correct)\n",
    "\n",
    "    \n",
    "print('epoch\\tAccuracy\\tLoss')\n",
    "for epoch in range(num_of_epochs):\n",
    "    train(loaders['train'], cnn, loss_func, optimizer)\n",
    "    print(\n",
    "    \"{}\\t{}\\t{}\".format(epoch + 1, round(total_train_acc[epoch], 5), round(total_train_loss[epoch], 5)))\n",
    "\n",
    "# Save the model \n",
    "torch.save(cnn.state_dict(), \"Resnet50model.pth\")\n",
    "files.download('Resnet50model.pth') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3) Test\n",
    "------------------------------------------"
   ],
   "metadata": {
    "id": "tYIB4Fzmgx_l"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_rYWNZCB4OzI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "outputId": "c50bd41c-1a26-45d4-f9b5-7ecf299b78db"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "download(\"download_133c855f-4b7c-437d-9f2b-8cf32f90f2a2\", \"kaggleComp.csv\", 3292)"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Find the correct label \n",
    "def getkey(item):\n",
    "    for key, value in train_data.class_to_idx.items():\n",
    "        if value == item:\n",
    "            return key\n",
    "\n",
    "# Test function\n",
    "def test(dataloader, model):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, img_number) in enumerate(dataloader, 0):\n",
    "            img_number = img_number[0]\n",
    "            images = images.to(device)\n",
    "            outputs = cnn(images)\n",
    "            _ , predicted = torch.max(outputs, dim=1)\n",
    "            predictions.append([img_number,predicted.cpu().item()])\n",
    "        return predictions \n",
    "\n",
    "\n",
    "cnn.load_state_dict(torch.load('Resnet50model.pth', map_location=torch.device(device)))\n",
    "\n",
    "# Testing\n",
    "predictions = test(loaders['test'], cnn)\n",
    "\n",
    "# Ouput the csv file for Kaggle submission\n",
    "df = pd.DataFrame(predictions, columns=['id','category'])\n",
    "df['category'] = df['category'].apply(getkey)\n",
    "df.astype(int).sort_values(by='id').to_csv('kaggleComp.csv', index=False)\n",
    "files.download('kaggleComp.csv') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CS480_KaggleComp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}